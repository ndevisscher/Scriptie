{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "from lxml import etree \n",
    "from bz2file import BZ2File\n",
    "import bz2\n",
    "import codecs\n",
    "import xml\n",
    "import glob\n",
    "import os\n",
    "import bs4\n",
    "import collections\n",
    "import itertools\n",
    "import math\n",
    "import networkx as nx\n",
    "import community\n",
    "import pickle\n",
    "import plotly.plotly as py\n",
    "from collections import defaultdict, Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from pattern.nl import parsetree, pprint, singularize, pluralize\n",
    "from pattern.metrics import readability\n",
    "from xml import parsers\n",
    "import xml.parsers.expat\n",
    "from xml.etree import cElementTree as ET\n",
    "from xml.dom.minidom import parse\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Troonrede parsing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lol_l\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "def parse_troonrede(f):\n",
    "    '''Read a troonrede file, extract all text and output a list of lists, \n",
    "    each element is a paragraph containing a list of sentences,\n",
    "    each sentence is parsed.'''\n",
    "    soup= BeautifulSoup(open(f).read())\n",
    "    ourdiv=soup.find('div', id=\"post-content\") \n",
    "    ourpars= [parsetree(p.text, lemmata=True, Relations=True) for p in ourdiv.findAll('p')[1:-1]]\n",
    "    return ourpars\n",
    "\n",
    "# this applies step 2 to all troonredes \n",
    "def parse_corpus(folder):\n",
    "    alltroonredes= glob.glob(os.path.join(folder, '*.html'))\n",
    "    troonredes={}\n",
    "    for troonrede in alltroonredes:\n",
    "        key= troonrede.split('\\\\')[1].replace('.html','')\n",
    "        value= parse_troonrede(troonrede)\n",
    "        troonredes[key]=value\n",
    "    return troonredes\n",
    "\n",
    "parsedtroonredes= parse_corpus('files')\n",
    "print \"Troonrede parsing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Gehele corpus met lemmatiseren'''\n",
    "def processText(parsedcorpus):\n",
    "    wordsPerPara= [list([ w.lemma for s in p for w in s.nouns])  for p in parsedcorpus  ]\n",
    "    return wordsPerPara\n",
    "\n",
    "tekst= {k:processText(parsedtroonredes[k]) for k in parsedtroonredes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Alle gelemmatiseerde woorden en hoevaak ze voorkomen in het corpus'''\n",
    "lemmaDict = {}\n",
    "for troonrede in sorted(tekst):\n",
    "    for paragraph in tekst[troonrede]:\n",
    "        for word in paragraph:\n",
    "            try:\n",
    "                if str(word) in lemmaDict:\n",
    "                    lemmaDict[str(word)] += 1\n",
    "                else:\n",
    "                    lemmaDict[str(word)] = 1\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Gebruikt de dictionary van gelemmatiseerde woorden om een dictionary te maken van alle mogelijke combinaties van 2 woorden'''\n",
    "wordlist = []\n",
    "fullCombiDict = {}\n",
    "for word in lemmaDict:\n",
    "    word = re.sub(r'[^\\w]', '', word)\n",
    "    if len(word) > 2:\n",
    "        wordlist.append(word)\n",
    "for combi in itertools.combinations(sorted(wordlist),2):\n",
    "    fullCombiDict[combi] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dataPerYear bevat per jaar: aantal paragrafen, aantal zinnen, aantal woorden en aantal lettergrepen in de gehele troonrede\n",
      "- redes bevat per jaar de gehele troonrede als tekst\n"
     ]
    }
   ],
   "source": [
    "'''Per jaar de hoeveelheid paragrafen, zinnen en woorden'''\n",
    "redes = {}\n",
    "dataPerYear = {}\n",
    "for troonrede in parsedtroonredes:\n",
    "    year = troonrede\n",
    "    paragraphs = 0\n",
    "    sentences = 0\n",
    "    words = 0\n",
    "    syllables = 0\n",
    "    rede = []\n",
    "    for paragraph in parsedtroonredes[troonrede]:\n",
    "        paragraphs += 1\n",
    "        sentences += len(paragraph)\n",
    "        for sentence in paragraph:\n",
    "            words += len(sentence)\n",
    "            for word in sentence:\n",
    "                if word.string == \".\" or word.string == \",\":\n",
    "                    rede.append(word.string)\n",
    "                else:\n",
    "                    rede.append(word.string)\n",
    "                    try:\n",
    "                        syllables += syllablesCount(word.string)\n",
    "                    except:\n",
    "                        pass\n",
    "    redes[year] = rede            \n",
    "    info = [paragraphs,sentences,words,syllables]\n",
    "    dataPerYear[year] = info\n",
    "print \"- dataPerYear bevat per jaar: aantal paragrafen, aantal zinnen, aantal woorden en aantal lettergrepen in de gehele troonrede\"\n",
    "print \"- redes bevat per jaar de gehele troonrede als tekst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2491\n"
     ]
    }
   ],
   "source": [
    "paragraphCount = 0\n",
    "for year in dataPerYear:\n",
    "    paragraphCount += dataPerYear[year][0]\n",
    "print paragraphCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Bouwen van de collocatie dataframe voor alle troonredes'''\n",
    "yearCombiDict = {}\n",
    "for troonrede in tekst:\n",
    "    combiDict = {}\n",
    "    for paragraph in tekst[troonrede]:\n",
    "        words = []\n",
    "        for word in paragraph:\n",
    "            word = re.sub(r'[^\\w]', '', word)\n",
    "            if len(word) > 2:\n",
    "                words.append(word)\n",
    "        for combi in itertools.combinations(sorted(words),2):\n",
    "            if combi in fullCombiDict:\n",
    "                fullCombiDict[combi] += 1\n",
    "            else:\n",
    "                pass\n",
    "            if combi in combiDict:\n",
    "                combiDict[combi] += 1\n",
    "            else:\n",
    "                combiDict[combi] = 1\n",
    "    yearCombiDict[troonrede] = combiDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordParcount = {}\n",
    "combiParcount = {}\n",
    "\n",
    "for troonrede in sorted(tekst):\n",
    "    for paragraph in tekst[troonrede]:\n",
    "        for word1 in sorted(paragraph):\n",
    "            if len(word1.encode('utf-8')) > 1:\n",
    "                if word1.encode('utf-8') in wordParcount:\n",
    "                    wordParcount[word1.encode('utf-8')] += 1\n",
    "                else:\n",
    "                    wordParcount[word1.encode('utf-8')] = 1\n",
    "                for word2 in sorted(paragraph):\n",
    "                    if len(word2.encode('utf-8')) > 1:\n",
    "                        if word1.encode('utf-8') < word2.encode('utf-8'):\n",
    "                            if (word1.encode('utf-8'),word2.encode('utf-8')) in combiParcount:\n",
    "                                combiParcount[word1.encode('utf-8'),word2.encode('utf-8')] += 1\n",
    "                            else:\n",
    "                                combiParcount[word1.encode('utf-8'),word2.encode('utf-8')] = 1\n",
    "                \n",
    "for item in wordParcount:\n",
    "    wordParcount[item] = wordParcount[item]/float(paragraphCount)\n",
    "for item in combiParcount:\n",
    "    combiParcount[item] = combiParcount[item]/float(paragraphCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Functie om P(w) te berekenen'''\n",
    "def findW(word):\n",
    "    return float(wordParcount[word])\n",
    "\n",
    "'''Functie om P(w,c) te berekenen'''\n",
    "def findWC(W,C):\n",
    "    try:\n",
    "        return float(combiParcount[W,C])\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "'''Functie om I(w,c) te berekenen'''\n",
    "def findI(W1,W2):\n",
    "    total = 0.0\n",
    "    for word in wordParcount:\n",
    "        if word != W1 and word != W2:\n",
    "            part1 = findWC(W1,word)\n",
    "            part2 = findW(W1)\n",
    "            part3 = findW(word)\n",
    "            if part1 != 0 and (part2*part3) != 0: \n",
    "                check = math.log(part1/(part2*part3))\n",
    "                if check > 0:\n",
    "                    total += check\n",
    "    return total\n",
    "                \n",
    "'''Functie om de score S(w1,w2) te bepalen'''\n",
    "def score(W1,W2):\n",
    "    score = 0.0\n",
    "    part1 = findI(W1,W2)\n",
    "    if part1 == 0:\n",
    "        return score\n",
    "    part2 = findI(W2,W1)\n",
    "    if part2 == 0:\n",
    "        return score\n",
    "    score = min(part1,part2)/part1\n",
    "    return score\n",
    "\n",
    "# alvast code maken voor figuur 4 en kijken hoe die figuur gemaakt kan worden via pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Berekenen van de proximity score over alle collocaties'''\n",
    "def networkBuilder ():\n",
    "    output = {}\n",
    "    for combi in combiParcount:\n",
    "        if combi[0] != combi[1]:\n",
    "            weight = score(combi[0],combi[1])\n",
    "            if weight > 0:\n",
    "                output[combi] = weight\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135.77914892941237"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "findI(\"wet\",\"kabinet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 10min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "netwerkDict = networkBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Opslaan van het netwerk dictionary naar pickle'''\n",
    "pickle.dump( netwerkDict, open( \"netwerkFull.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "insecure string pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fbaeabaf9474>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Openen van een opgeslagen dictionary vanuit pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnetwerkDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"netwerk.p\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\lol_l\\Anaconda2\\lib\\pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lol_l\\Anaconda2\\lib\\pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lol_l\\Anaconda2\\lib\\pickle.pyc\u001b[0m in \u001b[0;36mload_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    970\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"insecure string pickle\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m                 \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: insecure string pickle"
     ]
    }
   ],
   "source": [
    "#Openen van een opgeslagen dictionary vanuit pickle\n",
    "netwerkDict = pickle.load( open( \"netwerk.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['info']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "'''Vergroten van de graphs zodat ze duidelijker zijn'''\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = 16, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6cAAAK+CAYAAABesmiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbe29b860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc14c8438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Creeëren van de weighted graph vanuit de gevonden similarity scores'''\n",
    "G = nx.Graph()\n",
    "for item in netwerkDict:\n",
    "    G.add_edge(item[0],item[1],weight=netwerkDict[item])\n",
    "    \n",
    "pos=nx.spring_layout(G) # positions for all nodes\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G,pos,node_size=200)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G,pos, width=4)\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G,pos,font_size=10,font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig(\"weighted_graph.png\") # save as png\n",
    "plt.figure(figsize=(1000,1000))\n",
    "plt.show() # display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learn about API authentication here: https://plot.ly/python/getting-started\n",
    "# Find your api_key here: https://plot.ly/settings/api\n",
    "\n",
    "# create our stacked data manually\n",
    "y0 = np.random.rand(100)\n",
    "y1 = y0 + np.random.rand(100)\n",
    "y2 = y1 + np.random.rand(100)\n",
    "capacity = 3*np.ones(100)\n",
    "\n",
    "# make the mpl plot (no fill yet)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y0, label='y0')\n",
    "ax.plot(y1, label='y1')\n",
    "ax.plot(y2, label='y2')\n",
    "ax.plot(capacity, label='capacity')\n",
    "\n",
    "# set all traces' \"fill\" so that it fills to the next 'y' trace\n",
    "update = {'data':[{'fill': 'tonexty'}]}\n",
    "\n",
    "# strip style just lets Plotly make the styling choices (e.g., colors)\n",
    "plot_url = py.plot_mpl(fig, update=update, strip_style=True, filename='mpl-stacked-line')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
